{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "from six.moves import xrange  # pylint: disable=redefined-builtin\n",
    "import tensorflow as tf\n",
    "import PIL.Image as Image\n",
    "import random\n",
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "import time\n",
    "import sys\n",
    "sys.path.insert(1,'/home/sclab/Master/I3D-Tensorflow/')\n",
    "import input_data\n",
    "import math\n",
    "from i3d import InceptionI3d\n",
    "from utils import *\n",
    "from tensorflow.python import pywrap_tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename='/home/sclab/Master/I3D-Tensorflow/list/hmdb_list/train_rgb.list'\n",
    "batch_size=6 \n",
    "num_frames_per_clip=64\n",
    "crop_size=224\n",
    "shuffle=True\n",
    "gpu_num = 1\n",
    "num_frame_per_clib = 64\n",
    "rgb_channels = 3\n",
    "flow_channels = 2\n",
    "classics = 8\n",
    "model_save_dir = '/home/sclab/Master/I3D-Tensorflow/experiments/hmdb-51/models/flow_scratch_20000_6_64_0.0001_decay'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frames_data(filename, num_frames_per_clip, sample_rate, add_flow):\n",
    "    ''' Given a directory containing extracted frames, return a video clip of\n",
    "    (num_frames_per_clip) consecutive frames as a list of np arrays '''\n",
    "    #print(filename)\n",
    "    filename_i = os.path.join(filename, 'i')\n",
    "    #print(filename)\n",
    "    rgb_ret_arr, s_index = get_data(filename, num_frames_per_clip, sample_rate)\n",
    "    if not add_flow:\n",
    "        return rgb_ret_arr, [], s_index\n",
    "    filename_x = os.path.join(filename, 'x')\n",
    "    flow_x, _ = get_data(filename_x, num_frames_per_clip, sample_rate, s_index)\n",
    "    flow_x = np.expand_dims(flow_x, axis=-1)\n",
    "    filename_y = os.path.join(filename, 'y')\n",
    "    flow_y, _ = get_data(filename_y, num_frames_per_clip, sample_rate, s_index)\n",
    "    flow_y = np.expand_dims(flow_y, axis=-1)\n",
    "    flow_ret_arr = np.concatenate((flow_x, flow_y), axis=-1)\n",
    "    return rgb_ret_arr, flow_ret_arr, s_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_process(tmp_data, crop_size):\n",
    "    img_datas = []\n",
    "    crop_x = 0\n",
    "    crop_y = 0\n",
    "    for j in xrange(len(tmp_data)):\n",
    "        img = Image.fromarray(tmp_data[j].astype(np.uint8))\n",
    "        if img.width > img.height:\n",
    "            scale = float(256) / float(img.height)\n",
    "            img = np.array(cv2.resize(np.array(img), (int(img.width * scale + 1), 256))).astype(np.float32)\n",
    "        else:\n",
    "            scale = float(256) / float(img.width)\n",
    "            img = np.array(cv2.resize(np.array(img), (256, int(img.height * scale + 1)))).astype(np.float32)\n",
    "        if j == 0:\n",
    "            # crop_x = random.randint(0, int(img.shape[0] - crop_size))\n",
    "            # crop_y = random.randint(0, int(img.shape[1] - crop_size))\n",
    "            crop_x = int((img.shape[0] - crop_size) / 2)\n",
    "            crop_y = int((img.shape[1] - crop_size) / 2)\n",
    "        img = img[crop_x:crop_x + crop_size, crop_y:crop_y + crop_size, :]\n",
    "        img_datas.append(img)\n",
    "    return img_datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(filename, num_frames_per_clip, sample_rate, s_index=-1):\n",
    "#     print (filename)\n",
    "    ret_arr = []\n",
    "    filenames = ''\n",
    "    for parent, dirnames, filenames in os.walk(filename):\n",
    "        print (len(filenames))\n",
    "        if len(filenames)==0:\n",
    "            print('DATA_ERRO: %s'%filename)\n",
    "            return [], s_index\n",
    "        if (len(filenames)-s_index) <= num_frames_per_clip:\n",
    "            filenames = sorted(filenames)\n",
    "            if len(filenames) < num_frames_per_clip:\n",
    "                for i in range(num_frames_per_clip):\n",
    "                    if i >= len(filenames):\n",
    "                        i = len(filenames)-1\n",
    "                    image_name = str(filename) + '/' + str(filenames[i])\n",
    "                    img = Image.open(image_name)\n",
    "                    img_data = np.array(img)\n",
    "                    ret_arr.append(img_data)\n",
    "            else:\n",
    "                for i in range(num_frames_per_clip):\n",
    "                    image_name = str(filename) + '/' + str(filenames[len(filenames)-num_frames_per_clip+i])\n",
    "                    img = Image.open(image_name)\n",
    "                    img_data = np.array(img)\n",
    "                    ret_arr.append(img_data)\n",
    "            return sample_data(ret_arr, num_frames_per_clip, sample_rate), s_index\n",
    "    filenames = sorted(filenames)\n",
    "    if s_index < 0:\n",
    "        s_index = random.randint(0, len(filenames) - num_frames_per_clip)\n",
    "    for i in range(int(num_frames_per_clip/sample_rate)):\n",
    "        image_name = str(filename) + '/' + str(filenames[int(i*sample_rate)+s_index])\n",
    "        img = Image.open(image_name)\n",
    "        img_data = np.array(img)\n",
    "        ret_arr.append(img_data)\n",
    "    return ret_arr, s_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = open(filename, 'r')\n",
    "read_dirnames = []\n",
    "rgb_data = []\n",
    "flow_data = []\n",
    "label = []\n",
    "batch_index = 0\n",
    "next_batch_start = -1\n",
    "lines = list(lines)\n",
    "sample_rate=1\n",
    "start_pos=-1\n",
    "add_flow=False\n",
    "# lines = filename\n",
    "# Forcing shuffle, if start_pos is not specified\n",
    "# if start_pos < 0:\n",
    "shuffle = False\n",
    "if shuffle:\n",
    "    video_indices = list(range(len(lines)))\n",
    "    random.seed(time.time())\n",
    "    random.shuffle(video_indices)\n",
    "else:\n",
    "    # Process videos sequentially\n",
    "    video_indices = range(start_pos, len(lines))\n",
    "for index in video_indices:\n",
    "    if batch_index >= batch_size:\n",
    "        next_batch_start = index\n",
    "        break\n",
    "    line = lines[index].strip('\\n').split()\n",
    "#     print (line)\n",
    "    dirname = line[0]\n",
    "    tmp_label = line[1]\n",
    "    if not shuffle:\n",
    "        print(\"Loading a video clip from {}...\".format(dirname))\n",
    "    tmp_rgb_data, tmp_flow_data, _ = get_frames_data(dirname, num_frames_per_clip, sample_rate, add_flow)\n",
    "    if len(tmp_rgb_data) != 0:\n",
    "        rgb_img_datas = data_process(tmp_rgb_data, crop_size)\n",
    "        if add_flow:\n",
    "            flow_img_datas = data_process(tmp_flow_data, crop_size)\n",
    "            flow_data.append(flow_img_datas)\n",
    "        rgb_data.append(rgb_img_datas)\n",
    "        label.append(int(tmp_label))\n",
    "        batch_index = batch_index + 1\n",
    "        read_dirnames.append(dirname)\n",
    "\n",
    "# pad (duplicate) data/label if less than batch_size\n",
    "# print (rgb_data)\n",
    "valid_len = len(rgb_data)\n",
    "print (valid_len)\n",
    "pad_len = 12 - valid_len\n",
    "print (pad_len)\n",
    "if pad_len:\n",
    "    for i in range(pad_len):\n",
    "        rgb_data.append(rgb_data[-1])\n",
    "#         flow_data.append(flow_data[-1])\n",
    "        label.append(int(label[-1]))\n",
    "\n",
    "np_arr_rgb_data = np.array(rgb_data).astype(np.float32)\n",
    "np_arr_flow_data = np.array(flow_data).astype(np.float32)\n",
    "np_arr_label = np.array(label).astype(np.int64)\n",
    "\n",
    "# return np_arr_rgb_data, np_arr_flow_data, np_arr_label.reshape(batch_size), next_batch_start, read_dirnames, valid_len\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np_arr_rgb_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(model_save_dir):\n",
    "    os.makedirs(model_save_dir)\n",
    "rgb_pre_model_save_dir = \"/home/sclab/Master/I3D-Tensorflow/checkpoints/rgb_imagenet/\"\n",
    "\n",
    "with tf.Graph().as_default():\n",
    "    global_step = tf.get_variable(\n",
    "                    'global_step',\n",
    "                    [],\n",
    "                    initializer=tf.constant_initializer(0),\n",
    "                    trainable=False\n",
    "                    )\n",
    "    rgb_images_placeholder, flow_images_placeholder, labels_placeholder, is_training = placeholder_inputs(\n",
    "                    batch_size * gpu_num,\n",
    "                    num_frame_per_clib,\n",
    "                    crop_size,\n",
    "                    rgb_channels,\n",
    "                    flow_channels\n",
    "                    )\n",
    "\n",
    "    learning_rate = tf.train.exponential_decay(learning_rate, global_step, decay_steps=3000, decay_rate=0.1, staircase=True)\n",
    "    opt_rgb = tf.train.AdamOptimizer(learning_rate)\n",
    "    #opt_stable = tf.train.MomentumOptimizer(learning_rate, 0.9)\n",
    "    with tf.variable_scope('RGB'):\n",
    "        rgb_logit, _ = InceptionI3d(\n",
    "                                num_classes=classics,\n",
    "                                spatial_squeeze=True,\n",
    "                                final_endpoint='Logits'\n",
    "                                )(rgb_images_placeholder, is_training)\n",
    "    rgb_loss = tower_loss(\n",
    "                            rgb_logit,\n",
    "                            labels_placeholder\n",
    "                            )\n",
    "    accuracy = tower_acc(rgb_logit, labels_placeholder)\n",
    "    update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "    with tf.control_dependencies(update_ops):\n",
    "        rgb_grads = opt_rgb.compute_gradients(rgb_loss)\n",
    "        apply_gradient_rgb = opt_rgb.apply_gradients(rgb_grads, global_step=global_step)\n",
    "        train_op = tf.group(apply_gradient_rgb)\n",
    "        null_op = tf.no_op()\n",
    "\n",
    "    # Create a saver for loading trained checkpoints.\n",
    "    rgb_variable_map = {}\n",
    "    for variable in tf.global_variables():\n",
    "        if variable.name.split('/')[0] == 'RGB' and 'Adam' not in variable.name.split('/')[-1] and variable.name.split('/')[2] != 'Logits':\n",
    "            # rgb_variable_map[variable.name.replace(':0', '')[len('RGB/inception_i3d/'):]] = variable\n",
    "            rgb_variable_map[variable.name.replace(':0', '')] = variable\n",
    "    rgb_saver = tf.train.Saver(var_list=rgb_variable_map, reshape=True)\n",
    "\n",
    "    # Create a saver for writing training checkpoints.\n",
    "    saver = tf.train.Saver()\n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "    # Create a session for running Ops on the Graph.\n",
    "    sess = tf.Session(\n",
    "                    config=tf.ConfigProto(allow_soft_placement=True)\n",
    "                    )\n",
    "    sess.run(init)\n",
    "    # Create summary writter\n",
    "    tf.summary.scalar('accuracy', accuracy)\n",
    "    tf.summary.scalar('rgb_loss', rgb_loss)\n",
    "    tf.summary.scalar('learning_rate', learning_rate)\n",
    "    merged = tf.summary.merge_all()\n",
    "# load pre_train models\n",
    "ckpt = tf.train.get_checkpoint_state(rgb_pre_model_save_dir)\n",
    "print (ckpt)\n",
    "if ckpt and ckpt.model_checkpoint_path:\n",
    "    print(\"loading checkpoint %s,waiting......\" % ckpt.model_checkpoint_path)\n",
    "    rgb_saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "    print(\"load complete!\")\n",
    "\n",
    "train_writer = tf.summary.FileWriter('/home/sclab/Master/I3D-Tensorflow/visual_logs/train_rgb_imagenet_10000_6_64_0.0001_decay', sess.graph)\n",
    "test_writer = tf.summary.FileWriter('/home/sclab/Master/I3D-Tensorflow/visual_logs/test_rgb_imagenet_10000_6_64_0.0001_decay', sess.graph)\n",
    "for step in xrange(max_steps):\n",
    "    start_time = time.time()\n",
    "#         rgb_train_images, flow_train_images, train_labels, _, _, _ = input_data.read_clip_and_label(\n",
    "#                       filename='/home/sclab/Master/I3D-Tensorflow/list/hmdb_list/train_rgb.list',\n",
    "#                       batch_size=FLAGS.batch_size * gpu_num,\n",
    "#                       num_frames_per_clip=FLAGS.num_frame_per_clib,\n",
    "#                       crop_size=FLAGS.crop_size,\n",
    "#                       shuffle=True\n",
    "#                       )\n",
    "    # print (rgb_train_images)\n",
    "    # print (rgb_train_images.shape())\n",
    "    sess.run(train_op, feed_dict={\n",
    "                  rgb_images_placeholder: rgb_train_images,\n",
    "                  labels_placeholder: train_labels,\n",
    "                  is_training: True\n",
    "                  })\n",
    "    duration = time.time() - start_time\n",
    "    print('Step %d: %.3f sec' % (step, duration))\n",
    "\n",
    "    # Save a checkpoint and evaluate the model periodically.\n",
    "    if step % 10 == 0 or (step + 1) == FLAGS.max_steps:\n",
    "        print('Training Data Eval:')\n",
    "        summary, acc, loss_rgb = sess.run(\n",
    "                        [merged, accuracy, rgb_loss],\n",
    "                        feed_dict={rgb_images_placeholder: rgb_train_images,\n",
    "                                   labels_placeholder: train_labels,\n",
    "                                   is_training: False\n",
    "                                  })\n",
    "        print(\"accuracy: \" + \"{:.5f}\".format(acc))\n",
    "        print(\"rgb_loss: \" + \"{:.5f}\".format(loss_rgb))\n",
    "        train_writer.add_summary(summary, step)\n",
    "        print('Validation Data Eval:')\n",
    "        rgb_val_images, flow_val_images, val_labels, _, _, _ = input_data.read_clip_and_label(\n",
    "                        filename='/home/sclab/Master/I3D-Tensorflow/list/hmdb_list/test_flow.list',\n",
    "                        batch_size=batch_size * gpu_num,\n",
    "                        num_frames_per_clip=num_frame_per_clib,\n",
    "                        crop_size=crop_size,\n",
    "                        shuffle=True\n",
    "                        )\n",
    "        summary, acc = sess.run(\n",
    "                        [merged, accuracy],\n",
    "                        feed_dict={\n",
    "                                    rgb_images_placeholder: rgb_val_images,\n",
    "                                    labels_placeholder: val_labels,\n",
    "                                    is_training: False\n",
    "                                  })\n",
    "        print(\"accuracy: \" + \"{:.5f}\".format(acc))\n",
    "        test_writer.add_summary(summary, step)\n",
    "    if (step+1) % 3000 == 0 or (step + 1) == FLAGS.max_steps:\n",
    "        saver.save(sess, os.path.join(model_save_dir, 'i3d_hmdb_model'), global_step=step)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
